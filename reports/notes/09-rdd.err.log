Traceback (most recent call last):
  File "C:\Users\moses\.venv\de300\Lib\site-packages\jupyter_cache\executors\utils.py", line 58, in single_nb_execution
    executenb(
  File "C:\Users\moses\.venv\de300\Lib\site-packages\nbclient\client.py", line 1305, in execute
    return NotebookClient(nb=nb, resources=resources, km=km, **kwargs).execute()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\moses\.venv\de300\Lib\site-packages\jupyter_core\utils\__init__.py", line 165, in wrapped
    return loop.run_until_complete(inner)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\moses\AppData\Local\Programs\Python\Python311\Lib\asyncio\base_events.py", line 653, in run_until_complete
    return future.result()
           ^^^^^^^^^^^^^^^
  File "C:\Users\moses\.venv\de300\Lib\site-packages\nbclient\client.py", line 705, in async_execute
    await self.async_execute_cell(
  File "C:\Users\moses\.venv\de300\Lib\site-packages\nbclient\client.py", line 1058, in async_execute_cell
    await self._check_raise_for_error(cell, cell_index, exec_reply)
  File "C:\Users\moses\.venv\de300\Lib\site-packages\nbclient\client.py", line 914, in _check_raise_for_error
    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)
nbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:
------------------
print(collection_rdd_filter.collect())
------------------


[1;31m---------------------------------------------------------------------------[0m
[1;31mPy4JJavaError[0m                             Traceback (most recent call last)
Cell [1;32mIn[7], line 1[0m
[1;32m----> 1[0m [38;5;28mprint[39m([43mcollection_rdd_filter[49m[38;5;241;43m.[39;49m[43mcollect[49m[43m([49m[43m)[49m)

File [1;32m~\.venv\de300\Lib\site-packages\pyspark\rdd.py:1833[0m, in [0;36mRDD.collect[1;34m(self)[0m
[0;32m   1831[0m [38;5;28;01mwith[39;00m SCCallSiteSync([38;5;28mself[39m[38;5;241m.[39mcontext):
[0;32m   1832[0m     [38;5;28;01massert[39;00m [38;5;28mself[39m[38;5;241m.[39mctx[38;5;241m.[39m_jvm [38;5;129;01mis[39;00m [38;5;129;01mnot[39;00m [38;5;28;01mNone[39;00m
[1;32m-> 1833[0m     sock_info [38;5;241m=[39m [38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43mctx[49m[38;5;241;43m.[39;49m[43m_jvm[49m[38;5;241;43m.[39;49m[43mPythonRDD[49m[38;5;241;43m.[39;49m[43mcollectAndServe[49m[43m([49m[38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43m_jrdd[49m[38;5;241;43m.[39;49m[43mrdd[49m[43m([49m[43m)[49m[43m)[49m
[0;32m   1834[0m [38;5;28;01mreturn[39;00m [38;5;28mlist[39m(_load_from_socket(sock_info, [38;5;28mself[39m[38;5;241m.[39m_jrdd_deserializer))

File [1;32m~\.venv\de300\Lib\site-packages\py4j\java_gateway.py:1322[0m, in [0;36mJavaMember.__call__[1;34m(self, *args)[0m
[0;32m   1316[0m command [38;5;241m=[39m proto[38;5;241m.[39mCALL_COMMAND_NAME [38;5;241m+[39m\
[0;32m   1317[0m     [38;5;28mself[39m[38;5;241m.[39mcommand_header [38;5;241m+[39m\
[0;32m   1318[0m     args_command [38;5;241m+[39m\
[0;32m   1319[0m     proto[38;5;241m.[39mEND_COMMAND_PART
[0;32m   1321[0m answer [38;5;241m=[39m [38;5;28mself[39m[38;5;241m.[39mgateway_client[38;5;241m.[39msend_command(command)
[1;32m-> 1322[0m return_value [38;5;241m=[39m [43mget_return_value[49m[43m([49m
[0;32m   1323[0m [43m    [49m[43manswer[49m[43m,[49m[43m [49m[38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43mgateway_client[49m[43m,[49m[43m [49m[38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43mtarget_id[49m[43m,[49m[43m [49m[38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43mname[49m[43m)[49m
[0;32m   1325[0m [38;5;28;01mfor[39;00m temp_arg [38;5;129;01min[39;00m temp_args:
[0;32m   1326[0m     [38;5;28;01mif[39;00m [38;5;28mhasattr[39m(temp_arg, [38;5;124m"[39m[38;5;124m_detach[39m[38;5;124m"[39m):

File [1;32m~\.venv\de300\Lib\site-packages\pyspark\errors\exceptions\captured.py:179[0m, in [0;36mcapture_sql_exception.<locals>.deco[1;34m(*a, **kw)[0m
[0;32m    177[0m [38;5;28;01mdef[39;00m [38;5;21mdeco[39m([38;5;241m*[39ma: Any, [38;5;241m*[39m[38;5;241m*[39mkw: Any) [38;5;241m-[39m[38;5;241m>[39m Any:
[0;32m    178[0m     [38;5;28;01mtry[39;00m:
[1;32m--> 179[0m         [38;5;28;01mreturn[39;00m [43mf[49m[43m([49m[38;5;241;43m*[39;49m[43ma[49m[43m,[49m[43m [49m[38;5;241;43m*[39;49m[38;5;241;43m*[39;49m[43mkw[49m[43m)[49m
[0;32m    180[0m     [38;5;28;01mexcept[39;00m Py4JJavaError [38;5;28;01mas[39;00m e:
[0;32m    181[0m         converted [38;5;241m=[39m convert_exception(e[38;5;241m.[39mjava_exception)

File [1;32m~\.venv\de300\Lib\site-packages\py4j\protocol.py:326[0m, in [0;36mget_return_value[1;34m(answer, gateway_client, target_id, name)[0m
[0;32m    324[0m value [38;5;241m=[39m OUTPUT_CONVERTER[[38;5;28mtype[39m](answer[[38;5;241m2[39m:], gateway_client)
[0;32m    325[0m [38;5;28;01mif[39;00m answer[[38;5;241m1[39m] [38;5;241m==[39m REFERENCE_TYPE:
[1;32m--> 326[0m     [38;5;28;01mraise[39;00m Py4JJavaError(
[0;32m    327[0m         [38;5;124m"[39m[38;5;124mAn error occurred while calling [39m[38;5;132;01m{0}[39;00m[38;5;132;01m{1}[39;00m[38;5;132;01m{2}[39;00m[38;5;124m.[39m[38;5;130;01m\n[39;00m[38;5;124m"[39m[38;5;241m.[39m
[0;32m    328[0m         [38;5;28mformat[39m(target_id, [38;5;124m"[39m[38;5;124m.[39m[38;5;124m"[39m, name), value)
[0;32m    329[0m [38;5;28;01melse[39;00m:
[0;32m    330[0m     [38;5;28;01mraise[39;00m Py4JError(
[0;32m    331[0m         [38;5;124m"[39m[38;5;124mAn error occurred while calling [39m[38;5;132;01m{0}[39;00m[38;5;132;01m{1}[39;00m[38;5;132;01m{2}[39;00m[38;5;124m. Trace:[39m[38;5;130;01m\n[39;00m[38;5;132;01m{3}[39;00m[38;5;130;01m\n[39;00m[38;5;124m"[39m[38;5;241m.[39m
[0;32m    332[0m         [38;5;28mformat[39m(target_id, [38;5;124m"[39m[38;5;124m.[39m[38;5;124m"[39m, name, value))

[1;31mPy4JJavaError[0m: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.
: org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 2.0 failed 1 times, most recent failure: Lost task 1.0 in stage 2.0 (TID 9) (DESKTOP-QUFTBOJ.mshome.net executor driver): java.io.IOException: Cannot run program "python3": CreateProcess error=2, The system cannot find the file specified
	at java.lang.ProcessBuilder.start(Unknown Source)
	at org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:181)
	at org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:109)
	at org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:124)
	at org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:174)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:67)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
Caused by: java.io.IOException: CreateProcess error=2, The system cannot find the file specified
	at java.lang.ProcessImpl.create(Native Method)
	at java.lang.ProcessImpl.<init>(Unknown Source)
	at java.lang.ProcessImpl.start(Unknown Source)
	... 19 more

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2844)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2780)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2779)
	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2779)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1242)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1242)
	at scala.Option.foreach(Option.scala:407)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1242)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3048)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2982)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2971)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:984)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2398)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2419)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2438)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2463)
	at org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1046)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:407)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:1045)
	at org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:195)
	at org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)
	at java.lang.reflect.Method.invoke(Unknown Source)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
	at java.lang.Thread.run(Unknown Source)
Caused by: java.io.IOException: Cannot run program "python3": CreateProcess error=2, The system cannot find the file specified
	at java.lang.ProcessBuilder.start(Unknown Source)
	at org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:181)
	at org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:109)
	at org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:124)
	at org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:174)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:67)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	... 1 more
Caused by: java.io.IOException: CreateProcess error=2, The system cannot find the file specified
	at java.lang.ProcessImpl.create(Native Method)
	at java.lang.ProcessImpl.<init>(Unknown Source)
	at java.lang.ProcessImpl.start(Unknown Source)
	... 19 more


