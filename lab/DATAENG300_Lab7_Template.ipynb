{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff87e36d",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/mosesyhc/de300-wn2024-notes/blob/main/lab/DATAENG300_Lab7_Template.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500752d7-8255-4998-ab7a-a5015f5ff5f4",
   "metadata": {
    "id": "500752d7-8255-4998-ab7a-a5015f5ff5f4"
   },
   "source": [
    "# Lab 7 - Map Reduce for logistic regression\n",
    "\n",
    "**Before you begin**, make a copy of this notebook via `File -> Save a Copy` or `Copy to Drive` above.  Rename to include your name.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc652617-201b-4eed-b533-7eef93eb352b",
   "metadata": {
    "id": "fZlhfSfn56-S"
   },
   "source": [
    "---\n",
    "\n",
    "## Lab\n",
    "This lab applies map reduce to logistic regression with the titanic dataset.\n",
    "\n",
    "A logistic regression has the following log-likelihood function:\n",
    "\n",
    "$$\\displaystyle \\ell(\\beta) = \\sum_{i=1}^n y_i(\\beta^\\mathsf{T} \\mathbf{x_i}) - \\sum_{i=1}^n\\log (1 + \\exp\\{\\beta^\\mathsf{T} \\mathbf{x_i}\\})$$\n",
    "\n",
    "### Tasks\n",
    "Use `survived` as the response variable, and the other columns as predictors.\n",
    "1. Write the two appropriate `map` functions for calculating the log-likelihood function.\n",
    "    1. **Note:** the result $\\ell(\\beta)$ is just a number.  \n",
    "3. Return the log-likelihood function value at `beta = {'pclass': -1.11, 'age': -0.03, 'fare': 0.00, 'sex01': -2.5}` using the functions above.\n",
    "\n",
    "*Tip:* The linear regression example in class may be useful.  The complete notebook is found here: https://github.com/mosesyhc/de300-wn2024-notes/blob/main/examples/ex-linear-mr-complete.ipynb."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8103bc-fb38-4307-bfcd-8c7780f94bcb",
   "metadata": {},
   "source": [
    "### (Similar) PySpark setup in Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575235a4-1a46-49b4-9e40-ccb929095bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -q https://archive.apache.org/dist/spark/spark-3.4.0/spark-3.4.0-bin-hadoop3.tgz\n",
    "!tar xf spark-3.4.0-bin-hadoop3.tgz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa801aa-f815-46e5-b044-a1bc87cce17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q findspark\n",
    "!pip install -q seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6036e973-8c3c-44fc-badc-2cd0e861828f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark setup\n",
    "import os\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
    "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.4.0-bin-hadoop3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718852c6-bfae-4d34-8c31-ae7d908aad49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# findspark helps locate the environment variables\n",
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad76c937-54a2-4c6b-a2c8-d7f9051dcefe",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29abee00-3a3f-4e42-9773-3e7c40a7fc6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "titanic = sns.load_dataset('titanic', data_home='dataset/', cache=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151eb34c-fb48-4ccd-a718-730b050c86d7",
   "metadata": {
    "id": "fZlhfSfn56-S"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import IntegerType\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c978463-0313-416a-8b67-fbc82f36b450",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic = spark.read.csv('dataset/titanic.csv', header=True, inferSchema=True)\n",
    "\n",
    "# to focus on mapreduce, we only retain the following columns\n",
    "titanic = titanic \\\n",
    "          .select(['survived', 'pclass', 'sex', 'age', 'fare']) \\\n",
    "          .withColumn('sex01', (F.col('sex') == 'male').cast(IntegerType())) \\\n",
    "          .drop('sex')\n",
    "# the data are \"cleaned\" to obtain have complete data\n",
    "age_mean = titanic.groupBy().mean('Age').first()[0]\n",
    "titanic = titanic.na.fill({'Age': age_mean})\n",
    "# view summary of data\n",
    "titanic.describe().toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3183bd-cd66-4bad-ab9e-bcadf16e54f3",
   "metadata": {},
   "source": [
    "### Template code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea901b62-529e-46fe-b4a2-a57501f7cb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = ['pclass', 'age', 'fare', 'sex01']\n",
    "response = 'survived'\n",
    "\n",
    "# consider beta as fixed and callable from the maps\n",
    "beta = {'pclass': -1.11, 'age': -0.03, 'fare': 0.00, 'sex01': -2.5}  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e3aef7-fde1-4b71-acca-624278ae611a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# map\n",
    "def ybetax_map(row):\n",
    "  row = row.asDict()\n",
    "  for i in predictors:\n",
    "      yield  # returns the appropriate value given a row\n",
    "\n",
    "def logterm_map(row):\n",
    "  # we may use numpy functions np.log1p(), np.exp() in the map\n",
    "  row = row.asDict()\n",
    "  val = 0\n",
    "  for i in predictors:\n",
    "      val += ()\n",
    "  return  # returns the appropriate value given a row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36dadbec-7676-44e8-9343-4a910671e23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce\n",
    "# .reduce() directly maybe helpful since the result is a scalar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c75b89-4bcf-406d-bf26-b617d1f5817c",
   "metadata": {
    "id": "fZlhfSfn56-S"
   },
   "source": [
    "**Submission:**\n",
    "You will submit the `.ipynb` notebook file and any supporting information you see fit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fpCT90xsg7-l",
   "metadata": {
    "id": "fpCT90xsg7-l"
   },
   "source": [
    "# Generative AI disclosure\n",
    "In this course, you are generally allowed to use Generative Artificial Intelligence (GAI). Any use of GAI should be accompanied by a disclosure at the end of an assignment explaining (1) what you used GAI for; (2) the specific tool(s) you used; and (3) what prompts you used to get the results.\n",
    "\n",
    "**Include** any disclosure below."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
