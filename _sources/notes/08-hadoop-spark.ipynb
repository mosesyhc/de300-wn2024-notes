{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e66db65-c6b8-41d7-bed9-3b0b145ff0e0",
   "metadata": {},
   "source": [
    "# Distributed (cloud) computing\n",
    "\n",
    "This document covers the key elements for modern distributed computing, specifically a word on Hadoop and Spark.\n",
    "\n",
    "## Separation of compute from storage\n",
    "Traditionally compute and storage are colocated, e.g.,\n",
    "- a transactional database leverages its low-latency disk reads and high bandwidth.\n",
    "- even for distributed jobs, a *map* job locates the location of data and runs the *map* local to the data.\n",
    "\n",
    "Then why separate compute and storage?\n",
    "- Availability of cloud computing and storage purchase\n",
    "  - Cost: It is cheap to buy and host a server than to rent *if the server is up 24/7*, minus *maintenance cost*\n",
    "  - Towards ephermerality: (what we have done so far) Spin up an instance, use, and stop when done.\n",
    "  - Towards scalability: If you only need to run this titan job once a month, only pay for the resources then.\n",
    "- Data durability and availability\n",
    "  - Fault tolerance: Replication of data increases availability and mitgates a write operation that destroys data.\n",
    "\n",
    "### Hybridization of separation and colocation\n",
    "In reality, compute and storage are not either separated or colocated, e.g., \n",
    "- AWS elastic mapreduce (EMR) and S3\n",
    "- Spark infrastructure dependence on RAM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "444cb95b-a846-4927-8968-abf272004204",
   "metadata": {},
   "source": [
    "```{figure} ../img/hadoop-emr.png\n",
    "---\n",
    "width: 70%\n",
    "name: hadoop-emr\n",
    "---\n",
    "Instances as a processing cache in an ephemeral Hadoop cluster, Fig 6.7 from {cite:t}`reis2022fundamentals`. \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22584cb2-2bd0-4027-853c-dd41cbb0d398",
   "metadata": {},
   "source": [
    "## Hadoop\n",
    "\n",
    "Developed in 2006 to process data with the *MapReduce programming model* {cite:p}`dean2008mapreduce`, with the \"big data\" processing idea.\n",
    "\n",
    "Turned into an Apache project in 2008.\n",
    "\n",
    "Main components of Apache Hadoop:  \n",
    "\n",
    "- *Hadoop Distributed File System (HDFS)*: Manages large data sets running on commodity hardware (with data replication)\n",
    "- Yet Another Resource Negotiator (YARN)\n",
    "- *Hadoop MapReduce*: Splits data into blocks, distributes across different nodes, then runs task on each block in parallel\n",
    "- Hadoop Common (Hadoop Core): Common libraries and utilities\n",
    "\n",
    "*Why Hadoop is not enough?* \n",
    "- Hadoop utilizes external storage.  Read/write latency is high.\n",
    "- All codes must be restricted to a `map` and `reduce` constructs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e463003-2515-4c24-98be-813800ae68be",
   "metadata": {},
   "source": [
    "## Spark \n",
    "\n",
    "Spark was originally created at UC Berkeley's AMPLab in 2009 and open-sourced in 2010.\n",
    "\n",
    "Spark became an Apache project in 2013.\n",
    "\n",
    "Main components of Apache Spark:  \n",
    "\n",
    "- Spark Core: Execution engine for resource coordination\n",
    "- *Spark SQL*\n",
    "- *Machine Learning Library (MLlib)*\n",
    "- Spark Streaming: Capability for processing streaming data\n",
    "- GraphX: Capability for processing graph-based data\n",
    "\n",
    "Spark essentially tackles *only* where Hadoop does not perform well, by using an *in-memory* distributed computing engine.\n",
    "\n",
    "Spark:\n",
    "- makes use of Resilient Distributed Dataset (RDD)\n",
    "- employs dynamic RAM in processing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb39f96e-803f-40a3-af5e-85d64ba1b6ee",
   "metadata": {},
   "source": [
    "## Comparison of Hadoop and Spark (*adapted from* AWS summary)\n",
    "\n",
    "|               | Hadoop        |   Spark        |\n",
    "| :-----------: | :-----------: | :------------: |\n",
    "| Architecture     |  stores and processes data on external storage | stores and process data on internal memory |\n",
    "| Performance      | processes data in batches | processes data in real time |\n",
    "| Cost             | *relatively* affordable | comparatively more expensive |\n",
    "| Scalability      | easily scalable | comparatively more challenging |\n",
    "| Machine learning | needs to integrate with external libraries | built-in machine learning libraries |\n",
    "| Security         | strong security features, storage encryption, and access control | basic security |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e08d9d-415b-4995-8ae5-62b7a96a2d2c",
   "metadata": {},
   "source": [
    "## MapReduce"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a686ff43-b789-49cf-a2ae-51ec8c5438df",
   "metadata": {},
   "source": [
    "```{figure} ../img/mapreduce-trad.jpg\n",
    "---\n",
    "width: 70%\n",
    "name: mapreduce-trad\n",
    "---\n",
    "MapReduce schema from {cite:t}`tian2015energy`.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1d1569-fe6a-46c5-b276-2a235266450d",
   "metadata": {},
   "source": [
    "```{bibliography}\n",
    ":filter: docname in docnames\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
